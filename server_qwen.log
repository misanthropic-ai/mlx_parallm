INFO:mlx_parallm.cli:Starting server with initial model: NousResearch/Hermes-4-Qwen3-14B-1-e3
INFO:mlx_parallm.cli:Server will listen on 127.0.0.1:8000
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
INFO:     Started server process [31295]
INFO:     Waiting for application startup.
INFO:root:Batch config: MAX_BATCH_SIZE=8, BATCH_TIMEOUT=0.08s, REQUEST_TIMEOUT_SECONDS=600.0
INFO:root:Streaming concurrency limit: MAX_CONCURRENT_STREAMS=4
INFO:root:Attempting to load initial model from CLI: NousResearch/Hermes-4-Qwen3-14B-1-e3
INFO:root:Successfully loaded model: NousResearch/Hermes-4-Qwen3-14B-1-e3
INFO:root:Model NousResearch/Hermes-4-Qwen3-14B-1-e3 registered with status: loaded
INFO:root:Batch processing worker task created.
INFO:root:Streaming batch worker task created.
INFO:root:Batch processing worker starting. MAX_BATCH_SIZE=8, BATCH_TIMEOUT=0.08s
INFO:root:Batch worker successfully retrieved model 'NousResearch/Hermes-4-Qwen3-14B-1-e3'.
INFO:root:Streaming batch worker starting.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:55396 - "GET /health HTTP/1.1" 200 OK
INFO:root:Inside create_completion for model NousResearch/Hermes-4-Qwen3-14B-1-e3. Parsed stream flag: False, type: <class 'bool'>
INFO:root:Non-streaming completion request for model NousResearch/Hermes-4-Qwen3-14B-1-e3. It will be queued for batch processing.
INFO:root:Processing batch of 1 requests.
INFO:root:Calling batch_generate_text_util with 1 expanded prompts.
INFO:root:Batch fill=12.5% (queue_depth=0)
INFO:root:Using tokenizer's model_max_length: 131072
WARNING:root:Effective max_length 131072 exceeds safety cap of 65536. Capping to 65536.
INFO:root:Final effective_max_length for tokenizer: 65536
ERROR:root:Error during batch generation or result distribution: cannot access local variable 'suffixes' where it is not associated with a value
Traceback (most recent call last):
  File "/Users/shannon/Workspace/artivus/mlx_parallm/mlx_parallm/server/main.py", line 892, in batch_processing_worker
    unique_results: List[Tuple[str, int, int]] = await batch_generate_text_util(
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shannon/Workspace/artivus/mlx_parallm/mlx_parallm/utils.py", line 1327, in batch_generate_text
    generation_results = await loop.run_in_executor(None, _synchronous_generation)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shannon/Workspace/artivus/mlx_parallm/mlx_parallm/utils.py", line 1221, in _synchronous_generation
    est_suffix = max((len(s) for s in suffixes), default=0)
                                      ^^^^^^^^
UnboundLocalError: cannot access local variable 'suffixes' where it is not associated with a value
ERROR:root:Error processing request from queue for model NousResearch/Hermes-4-Qwen3-14B-1-e3: cannot access local variable 'suffixes' where it is not associated with a value
Traceback (most recent call last):
  File "/Users/shannon/Workspace/artivus/mlx_parallm/mlx_parallm/server/main.py", line 356, in create_completion
    response_data = await asyncio.wait_for(queued_req.future, timeout=REQUEST_TIMEOUT_SECONDS)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
           ^^^^^^^^^^^^
  File "/Users/shannon/Workspace/artivus/mlx_parallm/mlx_parallm/server/main.py", line 892, in batch_processing_worker
    unique_results: List[Tuple[str, int, int]] = await batch_generate_text_util(
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shannon/Workspace/artivus/mlx_parallm/mlx_parallm/utils.py", line 1327, in batch_generate_text
    generation_results = await loop.run_in_executor(None, _synchronous_generation)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shannon/Workspace/artivus/mlx_parallm/mlx_parallm/utils.py", line 1221, in _synchronous_generation
    est_suffix = max((len(s) for s in suffixes), default=0)
                                      ^^^^^^^^
UnboundLocalError: cannot access local variable 'suffixes' where it is not associated with a value
INFO:     127.0.0.1:55397 - "POST /v1/completions HTTP/1.1" 500 Internal Server Error
INFO:root:Streaming request received for model NousResearch/Hermes-4-Qwen3-14B-1-e3. Stream flag: True
INFO:     127.0.0.1:55398 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:55399 - "GET /debug/metrics HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [31295]
