BaseEnvConfig(
    group_size=2,
    max_num_workers=-1,
    max_eval_workers=16,
    max_num_workers_per_node=8,
    steps_per_eval=100,
    max_token_length=2048,
    eval_handling=<EvalHandlingEnum.STOP_TRAIN: 'STOP_TRAIN'>,
    eval_limit_ratio=0.5,
    inference_weight=1.0,
    batch_size=12,
    max_batches_offpolicy=3,
    tokenizer_name='NousResearch/Hermes-4-Qwen3-14B-1-e3',
    use_wandb=False,
    rollout_server_url='http://localhost:8001',
    total_steps=1000,
    wandb_name='gsm8k',
    num_rollouts_to_keep=32,
    num_rollouts_per_group_for_logging=1,
    ensure_scores_are_not_same=True,
    data_path_to_save_groups=None,
    data_dir_to_save_evals=None,
    min_items_sent_before_logging=2,
    include_messages=False,
    min_batch_allocation=None,
    worker_timeout=600.0
)
[
    APIServerConfig(
        timeout=1200,
        num_max_requests_at_once=512,
        num_requests_for_eval=256,
        model_name='NousResearch/Hermes-4-Qwen3-14B-1-e3',
        rolling_buffer_length=1000,
        server_type='openai',
        api_key='dummy',
        base_url='http://localhost:8000/v1',
        n_kwarg_is_ignored=False,
        health_check=True
    )
]
